#!/bin/bash

echo "üöÄ Installing requirements for Llama 3.2 11B Vision Model..."
echo "================================================"

# Update pip first
echo "üì¶ Updating pip..."
python -m pip install --upgrade pip

# Install PyTorch with CUDA support
echo "üî• Installing PyTorch with CUDA support..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Core transformers libraries
echo "ü§ó Installing Transformers ecosystem..."
pip install transformers>=4.40.0
pip install accelerate>=0.21.0
pip install safetensors>=0.3.1

# Quantization support
echo "‚ö° Installing quantization libraries..."
pip install bitsandbytes>=0.41.0

# Vision processing
echo "üëÅÔ∏è Installing vision libraries..."
pip install pillow>=9.5.0

# Hugging Face Hub for downloading
echo "üåê Installing Hugging Face Hub..."
pip install huggingface_hub>=0.16.0

# System monitoring utilities
echo "üìä Installing system monitoring..."
pip install psutil GPUtil

echo ""
echo "‚úÖ Installation completed!"
echo "üîç Verifying installation..."

# Verify CUDA
python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
else:
    print('‚ö†Ô∏è CUDA not available - model will run on CPU (very slow)')
"

# Verify Transformers
python -c "
import transformers
print(f'Transformers version: {transformers.__version__}')
"